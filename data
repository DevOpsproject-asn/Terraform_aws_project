KT session from real time CloudOps:

1. Allowing Role Access to RCA Notebook in Amazon Sagemaker:

   - Creating a policy in IAM via terraform to grant necessary permissions related to Sagemaker and assigned the appropriate ARN.
   - Converted JSON code to Terraform, incorporating the required changes in the policy resource.
   - Initiating a pull request (PR) in gitlab and seamlessly applied the Terraform changes after resolving any conflicts.

2. Bastion Server Connectivity:

   - Verifying connectivity from the bastion server to launch pad servers.
   - Conducting DNS lookups and checked security group (SG) settings in RDS for required ports.
   - Creating feature branch in GitHub and modified Terraform code (sg.tf) to include the necessary port (3306) for access.

3. EBS Volume Creation and Mounting on /apps:

   - Created and formatted an EBS volume using Terraform, incorporating modifications in aws_ebs_volume.tf and aws_volume_attachment.tf.
   - Executed commands like df -h and lsblk to confirm volume creation and mounting.
   - mkfs -t xfs /dev/nvme5n1 = to format a new and raw disk volume with xfs file system
     mount /dev/nvme5n1 /apps  = temporary mounting. It will vanish after reboot
   - Ensured persistence across reboots by updating /etc/fstab with the required mount information.

4. User Creation Using Ansible:

   - Configured user creation using Ansible, updating files like users.yml and users-vars.yml.
   - Modified key files including authorized_keys, id_rsa, and id_rsa.pub
   - vim /etc/ssh/sshd_config = to allow groups and user to ssh
   - Adjusted sshd_config to grant permissions for group ID and restarted the sshd service.

5. Ec2 creation using Terraform: 

   - Creating the below terraform files as per the requirement
     iam-roles.tf, iam-trust-policy-documents.tf, iam-policies.tf, iam-instance-profiles.tf & ec2-instances.tf
	 
6. Monitoring CPU Utilization of a Server using DataDog:

   - Accessed DataDog and navigated to Integrations -> Agent -> Amazon Linux.
   - Provided commands to be executed on the EC2 instance for starting the DataDog agent.
   - Demonstrated how to check the status of the DataDog agent using systemctl commands.
 
       systemctl start datadog-agent
       systemctl status datadog-agent
   - Configured DataDog alerts by selecting Monitors -> Manage -> choosing CPU -> defining metrics -> editing hostname
     By following the above steps, we can set the alarm for monitor CPU utilization from DD.

7. IAM User Creation via terraform:

   - First, trained us to write the terraform code for iam-users.tf, iam-policies.tf, iam-policy-documents.tf (converting json to terraform code).
   - After creating users & policies, created iam-groups.tf, iam-group-policy-attachments.tf and iam-group-membership.tf (Attaching policy to a group first then adding the same group to the User). 
   - After saving and commiting the code, created a Pull Request in order to apply in Terraform.

8. Password reset and User ID creation:

   - For User ID creation, first created Group ->   groupadd -g <groupID> <groupname>
   - Adding user to the group, useradd -g <groupID> -c "<useremailID>" <username>
         grep <username> /etc/passwd
   - Resetting the password need not to be expired for the particular user ID by using chage Linux command.

         history | grep chage
         chage -I -1 -m 0 -M 99999 -E -1 <Username>
		 
9. Increasing EBS Volume from Terraform:

    - Need to increase size from 45 to 50 GB in /var. In terraform code, modified the size 45 to 50 in ebs-volumes.tf. After that, creating a PR and applying in terraform after approval.
    - In order to updating the changes in AWS console, used this command -> sudo xfs_growfs -d /var
	
10. IAM Role creation in Terraform:

    - Initiated the process in Github Desktop by creating a new branch using the ticket number.
    - Demonstrated the creation of Terraform code for iam-roles.tf, iam-policies.tf, and iam-policy-documents.tf. This included the conversion of JSON to Terraform code.
    - Guided through the steps of saving and committing the code in the branch.
    - Showcased the creation of a Pull Request in Github, which is crucial for applying changes in Terraform.



Handling L1 & L2 JIRA tickets in CloudOps:-
 
1. Scheduling Carma Maintenance and EOM build for Monitoring via DataDog. 
2. Cloning the account in Github and creating role, policies and trust relationship policies from Visual Studio Console and sending the PR from github to Manager for approval.
3. Editing the security group and S3 bucket policies from console.
4. Managing SVN (SubVersion) Repository and extracting logs.
5. Editing and deleting AMI’s and EBS Volumes through Visual Studio Console and applying through Terraform.
6. Updating the secret keys in the repository level and assigning the value in Github.
7. Installing DataDog agent on ec2 instances.
8. Creating ECR repositories and adding the repo in Github under various accounts.
9. Deleting Ec2 instances along with ASG’s, ELB’s and ECS Clusters as per the requirement through Visual Studio Console and applying through Terraform.
10. Creating S3 bucket, IAM role and Cloudwatch groups and exporting the log files to S3 using AWS Lamda.
11. Adding/Modifying IAM policies in Terraform code as per the requirement.
12. Modifying the Python script in the Lamda function for the logs to be saved in the directories based on the Client’s requirement.
13. Creating new user ID in the Cloud bastion by using ansible script and emailing the Private keys to the user.
